{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Step1_AI면접관 Agent v1.0**"
      ],
      "metadata": {
        "id": "mSB2IiVH8B1v"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zU-xxYwejwGR"
      },
      "source": [
        "## **1. 환경준비**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CdcBWhy_F_Hm"
      },
      "source": [
        "### (1) 구글 드라이브"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1) 구글 드라이브 폴더 생성\n",
        "* 새 폴더(project_genai)를 생성하고\n",
        "* 제공 받은 파일을 업로드"
      ],
      "metadata": {
        "id": "xUOpvAJGGJnL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2) 구글 드라이브 연결"
      ],
      "metadata": {
        "id": "4jUC5td4GLEF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "tEfLUT6ZGEJi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6b2a5d59-e3ee-4702-c579-457c50c7f288"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### (2) 라이브러리"
      ],
      "metadata": {
        "id": "PepxmQuiGzkX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -r /content/drive/MyDrive/project_genai/requirements.txt -q"
      ],
      "metadata": {
        "id": "TwO3_Qx4PlM-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PS5BhycUFUMI"
      },
      "source": [
        "### (3) OpenAI API Key 확인\n",
        "* api_key.txt 파일에 다음의 키를 등록하세요.\n",
        "    * OPENAI_API_KEY\n",
        "    * NGROK_AUTHTOKEN"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "def load_api_keys(filepath=\"api_key.txt\"):\n",
        "    with open(filepath, \"r\") as f:\n",
        "        for line in f:\n",
        "            line = line.strip()\n",
        "            if line and \"=\" in line:\n",
        "                key, value = line.split(\"=\", 1)\n",
        "                os.environ[key.strip()] = value.strip()\n",
        "\n",
        "path = '/content/drive/MyDrive/project_genai/'\n",
        "# API 키 로드 및 환경변수 설정\n",
        "load_api_keys(path + 'api_key.txt')"
      ],
      "metadata": {
        "id": "AaZBGfeWNMRE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(os.environ['OPENAI_API_KEY'][:30])"
      ],
      "metadata": {
        "id": "GqSUhiv8wKxh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "30880564-ef85-436c-981f-69f708c78e65"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "sk-proj-r111drRrWBH3MHbjiUfFop\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **2. App.py**\n",
        "\n",
        "* 아래 코드에, Step1 혹은 고도화 된 Step2 파일 코드를 붙인다.\n",
        "    * 라이브러리\n",
        "    * 함수들과 그래프\n",
        "* Gradio 코드는 그대로 사용하거나 일부 수정 가능"
      ],
      "metadata": {
        "id": "ULAOaRHmShq1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile app.py\n",
        "\n",
        "## 1. 라이브러리 로딩 ---------------------------------------------\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "import openai\n",
        "import random\n",
        "import ast\n",
        "import fitz\n",
        "from docx import Document\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
        "\n",
        "from typing import Annotated, Literal, Sequence, TypedDict, List, Dict\n",
        "from langchain import hub\n",
        "from langchain_core.messages import BaseMessage, HumanMessage\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "from langchain_core.prompts import PromptTemplate, ChatPromptTemplate\n",
        "from langchain_openai import ChatOpenAI\n",
        "from langchain_community.embeddings import OpenAIEmbeddings\n",
        "from langchain_community.vectorstores import Chroma\n",
        "from langchain.output_parsers import CommaSeparatedListOutputParser\n",
        "from langgraph.graph import StateGraph, END\n",
        "\n",
        "## ---------------- 1단계 : 사전준비 ----------------------\n",
        "\n",
        "# 1) 파일 입력 --------------------\n",
        "def extract_text_from_file(file_path: str) -> str:\n",
        "    ext = os.path.splitext(file_path)[1].lower()\n",
        "    if ext == \".pdf\":\n",
        "        doc = fitz.open(file_path)\n",
        "        text = \"\\n\".join(page.get_text() for page in doc)\n",
        "        doc.close()\n",
        "        return text\n",
        "    elif ext == \".docx\":\n",
        "        doc = Document(file_path)\n",
        "        return \"\\n\".join(p.text for p in doc.paragraphs if p.text.strip())\n",
        "    else:\n",
        "        raise ValueError(\"지원하지 않는 파일 형식입니다. PDF 또는 DOCX만 허용됩니다.\")\n",
        "\n",
        "# 2) State 선언 --------------------\n",
        "from typing import TypedDict, List, Dict\n",
        "\n",
        "class ExamState(TypedDict):\n",
        "    # 고정 정보\n",
        "    exam_text: str\n",
        "    exam_summary: str\n",
        "    exam_keywords: List[str]\n",
        "    question_strategy: Dict[str, Dict]\n",
        "\n",
        "    # 문답 로그\n",
        "    current_question: str\n",
        "    current_answer: str\n",
        "    current_strategy: str\n",
        "    conversation: List[Dict[str, str]]\n",
        "    evaluation : List[Dict[str, str]]\n",
        "    next_step : str\n",
        "\n",
        "# 3) resume 분석 --------------------\n",
        "def analyze_exam(state: ExamState) -> ExamState:\n",
        "    exam_text = state.get(\"exam_text\", \"\")\n",
        "    if not exam_text:\n",
        "        raise ValueError(\"exam_text가 비어 있습니다. 먼저 텍스트를 추출해야 합니다.\")\n",
        "\n",
        "    llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0)\n",
        "\n",
        "    # 요약 프롬프트 구성\n",
        "    summary_prompt = ChatPromptTemplate.from_template(\n",
        "        '''당신은 고등학교 사회탐구 과목인 '정치와 법' 기출문제를 바탕으로 새로운 모의고사를 설계하는 AI입니다.\n",
        "        다음 기출문제 내용에서 새로운 문제를 만들기 위해 필요한 내용을 문제별로 모두 요약 해줘. 총 20개의 요약이 나와야해(요약시 ** 기호는 사용하지 말것):\\n\\n{exam_text}'''\n",
        "    )\n",
        "    formatted_summary_prompt = summary_prompt.format(exam_text=exam_text)\n",
        "    summary_response = llm.invoke(formatted_summary_prompt)\n",
        "    exam_summary = summary_response.content.strip()\n",
        "\n",
        "    # 키워드 추출 프롬프트 구성\n",
        "    keyword_prompt = ChatPromptTemplate.from_template(\n",
        "        '''당신은 고등학교 사회탐구 과목인 '정치와 법' 기출문제를 바탕으로 새로운 모의고사를 설계하는 AI입니다.\n",
        "        다음 기출문제 내용에서 새로운 문제를 만들기 위한 중요한 핵심 키워드를 문제당 1개씩 총 20개 추출해줘.\n",
        "        키워드는 그 문제에서 물어보는 고등학교 수능 개념을 추출해줘.\n",
        "        도출한 핵심 키워드만 쉼표로 구분해줘:\\n\\n{exam_text}'''\n",
        "    )\n",
        "    formatted_keyword_prompt = keyword_prompt.format(exam_text=exam_text)\n",
        "    keyword_response = llm.invoke(formatted_keyword_prompt)\n",
        "\n",
        "    parser = CommaSeparatedListOutputParser()\n",
        "    exam_keywords = parser.parse(keyword_response.content)\n",
        "\n",
        "    return {\n",
        "        **state,\n",
        "        \"exam_summary\": exam_summary,\n",
        "        \"exam_keywords\": exam_keywords,\n",
        "    }\n",
        "\n",
        "# 4) 질문 전략 수립 --------------------\n",
        "import json\n",
        "\n",
        "def generate_question_strategy(state: ExamState) -> ExamState:\n",
        "    exam_summary = state.get(\"exam_summary\", \"\")\n",
        "    exam_keywords = \", \".join(state.get(\"exam_keywords\", []))\n",
        "\n",
        "    prompt = ChatPromptTemplate.from_template(\"\"\"\n",
        "    당신은 고등학교 사회탐구 과목인 '정치와 법' 기출문제를 바탕으로 **수능형 사례 기반 5지선다형 모의고사**를 설계하는 AI입니다.\n",
        "\n",
        "    - 기출문제 요약:\n",
        "    {exam_summary}\n",
        "\n",
        "    - 기출문제 키워드:\n",
        "    {exam_keywords}\n",
        "\n",
        "      출제 조건:\n",
        "    - 문제는 반드시 2025학년도 기준 고등학교 '정치와 법' 교과서 및 수능·모의고사 범위 내에서만 출제하세요.\n",
        "    - 문제의 형식, 선택지 구성과 문제를 푸는 데 필요한 개념은 다음을 참고하되, 사례는 새롭게 구성하세요.\n",
        "    - 각 문제는 다음과 같은 구조여야 합니다:\n",
        "  {{\n",
        "    \"문제번호\": 1,\n",
        "    \"문제\": \"다음 사례에 대한 법적 판단으로 옳은 것은?\",\n",
        "    \"사례\": \"갑은 을과 혼인 후 A를 낳고 살다가 생활필수품 구매를 위해 친구 병으로부터 여러 차례 돈을 빌려 사용할 만큼 경제적 문제가 지속되자 결국 이혼 숙려 기간을 거쳐 이혼하였다. 한편 정과 무는 B와 C를 낳고 살았으나 무의 부정한 행위로 이혼하였으며 B는 정과, C는 무와 살기로 결정하였다. 몇 년 뒤, A를 홀로 양육하던 갑은 정과 혼인하였으며 정은 A를 친양자로 입양하였다. 이후 무가 갑작스런 사고로 사망하면서 갑은 B와 C를 친양자로 입양하였다.\"\",\n",
        "    \"선택지\": [\"① 갑과의 혼인 기간 동안 을은 갑이 병에게 빌린 생활필수품 구매 비용을 갚을 의무가 없다.\",\n",
        "     \"② 갑과 을의 이혼은 가정 법원에서 이혼 의사를 확인받는 즉시 그 효력이 발생한다.\",\n",
        "      \"③ 무는 정과의 이혼 시 혼인 중 공동으로 마련한 재산에 대해 재산 분할을 청구할 수 없다.\",\n",
        "       \"④ 정이 A를 입양함에 따라 을과 A의 친자 관계는 종료된다.\",\n",
        "        \"⑤ 입양으로 인해 B, C 모두 갑과 정의 혼인 외 출생자로 간주된다.\"],\n",
        "    \"정답\": \"④\"\n",
        "  }}\n",
        "        \"사례\" : \"\n",
        "    - 총 20개의 문제를 생성하고, 출력은 문제 리스트만 포함된 JSON 배열 형태로 출력하세요.\n",
        "\n",
        "       출력 형식 예시 (JSON 리스트만 출력):\n",
        "\n",
        "    [\n",
        "      {{\n",
        "        \"문제1\": \"다음 사례에 대한 법적 판단으로 옳은 것은?\"\n",
        "        \"사례\" : \"갑은 을과 혼인 후 A를 낳고 살다가 생활필수품 구매를 위해 친구 병으로부터 여러 차례 돈을 빌려 사용할 만큼 경제적 문제가 지속되자 결국 이혼 숙려 기간을 거쳐 이혼하였다. 한편 정과 무는 B와 C를 낳고 살았으나 무의 부정한 행위로 이혼하였으며 B는 정과, C는 무와 살기로 결정하였다. 몇 년 뒤, A를 홀로 양육하던 갑은 정과 혼인하였으며 정은 A를 친양자로 입양하였다. 이후 무가 갑작스런 사고로 사망하면서 갑은 B와 C를 친양자로 입양하였다.\"\n",
        "        \"선택지\": [\n",
        "          \"① 갑과의 혼인 기간 동안 을은 갑이 병에게 빌린 생활필수품 구매 비용을 갚을 의무가 없다.\",\n",
        "          \"② 갑과 을의 이혼은 가정 법원에서 이혼 의사를 확인받는 즉시 그 효력이 발생한다.\",\n",
        "          \"③ 무는 정과의 이혼 시 혼인 중 공동으로 마련한 재산에 대해 재산 분할을 청구할 수 없다.\",\n",
        "          \"④ 정이 A를 입양함에 따라 을과 A의 친자 관계는 종료된다.\",\n",
        "          \"⑤ 입양으로 인해 B, C 모두 갑과 정의 혼인 외 출생자로 간주된다.\"\n",
        "        ],\n",
        "        \"정답\": \"④\"\n",
        "      }},\n",
        "      ...\n",
        "    ]\n",
        "\n",
        "    ❗ 출력은 코드블럭 없이 반드시 순수 JSON 문자열만 출력해야 합니다.\n",
        "    ❗ 모든 키와 값은 큰따옴표(\")로 감싸야 하며, 정답은 반드시 \"①\", \"②\" 등의 문자열로 표시합니다.\n",
        "    \"\"\")\n",
        "\n",
        "    llm = ChatOpenAI(model=\"gpt-4o-mini\")\n",
        "    formatted_prompt = prompt.format(\n",
        "        exam_summary=exam_summary,\n",
        "        exam_keywords=exam_keywords\n",
        "    )\n",
        "    response = llm.invoke(formatted_prompt)\n",
        "    raw_output = response.content.strip()\n",
        "\n",
        "    # 코드블럭 제거\n",
        "    if \"```\" in raw_output:\n",
        "        import re\n",
        "        raw_output = re.sub(r\"```(?:json)?\", \"\", raw_output).replace(\"```\", \"\").strip()\n",
        "\n",
        "    # JSON 파싱\n",
        "    try:\n",
        "        question_list = json.loads(raw_output)\n",
        "    except json.JSONDecodeError as e:\n",
        "        raise ValueError(\"문제를 JSON으로 변환하는 데 실패했습니다.\\n원본:\\n\" + raw_output) from e\n",
        "\n",
        "    return {\n",
        "        **state,\n",
        "        \"question_strategy\": question_list  # 리스트 직접 저장\n",
        "    }\n",
        "\n",
        "\n",
        "\n",
        "# 5) 1단계 하나로 묶기 --------------------\n",
        "\n",
        "def preProcessing_Exam(file_path: str) -> ExamState:\n",
        "    # 파일에서 텍스트 추출\n",
        "    exam_text = extract_text_from_file(file_path)\n",
        "\n",
        "    # state 초기화\n",
        "    initial_state: ExamState = {\n",
        "        \"exam_text\": exam_text,\n",
        "        \"exam_summary\": '',\n",
        "        \"exam_keywords\": [],\n",
        "        \"question_strategy\": [],\n",
        "        \"current_question\": '',\n",
        "        \"current_answer\": '',\n",
        "        \"current_strategy\": '',\n",
        "        \"conversation\": [],\n",
        "        \"evaluation\": [],\n",
        "        \"next_step\": ''\n",
        "    }\n",
        "\n",
        "    # exam 분석 → 요약 및 키워드 생성 (예: LLM 요약)\n",
        "    state = analyze_exam(initial_state)\n",
        "\n",
        "    # 문제 리스트 생성\n",
        "    state = generate_question_strategy(state)\n",
        "\n",
        "    # 문제 리스트\n",
        "    question_list = state[\"question_strategy\"]\n",
        "\n",
        "    # 하나 선택\n",
        "    selected_question = random.choice(question_list)\n",
        "\n",
        "    return {\n",
        "        **state,\n",
        "        \"current_question\": selected_question,\n",
        "        \"current_strategy\": \"\"  # 주제 구분 없음\n",
        "    }\n",
        "\n",
        "\n",
        "\n",
        "## ---------------- 2단계 : 면접 Agent ----------------------\n",
        "\n",
        "import random\n",
        "import re\n",
        "from typing import Dict, Any\n",
        "\n",
        "ExamState = Dict[str, Any]  # 상태를 저장하는 타입\n",
        "\n",
        "# 사용자 답변을 상태에 저장\n",
        "def update_current_answer(state: ExamState, user_answer: str) -> ExamState:\n",
        "    return {\n",
        "        **state,\n",
        "        \"current_answer\": user_answer.strip()\n",
        "    }\n",
        "\n",
        "# 정답 여부만 판단하는 평가 함수\n",
        "def evaluate_answer(state: ExamState) -> ExamState:\n",
        "    current_question = state.get(\"current_question\", {})\n",
        "    current_answer = state.get(\"current_answer\", \"\").strip()\n",
        "\n",
        "    # 정답\n",
        "    correct_answer = current_question.get(\"정답\", \"\").strip()\n",
        "\n",
        "    # 사용자 입력이 정답과 일치하는지 확인\n",
        "    result = {\n",
        "        \"정답여부\": \"맞음\" if current_answer == correct_answer else \"틀림\",\n",
        "        \"정답\": correct_answer\n",
        "    }\n",
        "\n",
        "    # 대화 저장\n",
        "    state[\"conversation\"].append({\n",
        "        \"question\": current_question,\n",
        "        \"answer\": current_answer\n",
        "    })\n",
        "\n",
        "    # 평가 저장\n",
        "    evaluation = state.get(\"evaluation\", [])\n",
        "    result[\"question_index\"] = len(state[\"conversation\"]) - 1\n",
        "    evaluation.append(result)\n",
        "\n",
        "    return {\n",
        "        **state,\n",
        "        \"evaluation\": evaluation\n",
        "    }\n",
        "\n",
        "\n",
        "\n",
        "# 3) 문제풀이 진행 검토 --------------------\n",
        "def decide_next_step(state: ExamState) -> ExamState:\n",
        "    conversation = state.get(\"conversation\", [])\n",
        "\n",
        "    # (1) 총 질문이 20개를 초과하면 종료\n",
        "    if len(conversation) >= 20:\n",
        "        next_step = \"end\"\n",
        "\n",
        "    # (2) 아직 문제 남아있으면 추가 질문\n",
        "    else:\n",
        "        next_step = \"additional_question\"\n",
        "\n",
        "    return {\n",
        "        **state,\n",
        "        \"next_step\": next_step\n",
        "    }\n",
        "\n",
        "# 4) 해설 생성 --------------------\n",
        "def generate_explanation(state: ExamState) -> ExamState:\n",
        "    llm = ChatOpenAI(model=\"gpt-4o-mini\")\n",
        "    current_question = state.get(\"current_question\", {})\n",
        "    question_text = current_question.get(\"문제\", \"\")\n",
        "    choices = \"\\n\".join(current_question.get(\"선택지\", []))\n",
        "    correct_answer = current_question.get(\"정답\", \"\")\n",
        "\n",
        "    prompt = ChatPromptTemplate.from_template(\"\"\"\n",
        "당신은 '정치와 법' 과목 수능형 객관식 문제에 대한 해설을 작성하는 AI입니다.\n",
        "\n",
        "아래는 문제와 선택지, 정답입니다:\n",
        "- 문제: {question_text}\n",
        "- 선택지:\n",
        "{choices}\n",
        "- 정답: {correct_answer}\n",
        "\n",
        "이 문제에 대한 **해설(풀이 과정)**을 작성하세요.\n",
        "학생이 이해할 수 있도록 문제를 어떤 법적 개념과 판례를 통해 해결해야 하는지 구체적으로 설명하세요.\n",
        "답의 근거뿐 아니라, 오답이 왜 틀렸는지도 간략히 설명하세요.\n",
        "\n",
        "형식: 한 문단으로 구성하며, 학생이 공부에 활용할 수 있도록 친절하고 명확하게 작성하세요.\n",
        "\"\"\")\n",
        "\n",
        "    formatted_prompt = prompt.format(\n",
        "        question_text=question_text,\n",
        "        choices=choices,\n",
        "        correct_answer=correct_answer\n",
        "    )\n",
        "\n",
        "    response = llm.invoke(formatted_prompt)\n",
        "    explanation = response.content.strip()\n",
        "\n",
        "    # 해설 저장\n",
        "    current_question[\"해설\"] = explanation\n",
        "\n",
        "    # 사용한 문제 제외하고 새로운 문제 선택\n",
        "    used_questions = [turn[\"question\"] for turn in state[\"conversation\"]]\n",
        "    remaining_questions = [q for q in state[\"question_strategy\"] if q not in used_questions]\n",
        "\n",
        "    if remaining_questions:\n",
        "        next_question = random.choice(remaining_questions)\n",
        "    else:\n",
        "        next_question = {\"문제\": \"모든 문제가 출제되었습니다.\", \"선택지\": [], \"사례\": \"\"}\n",
        "\n",
        "    return {\n",
        "        **state,\n",
        "        \"current_question\": next_question,\n",
        "        \"current_answer\": \"\"\n",
        "    }\n",
        "\n",
        "\n",
        "# 5) 문제풀이 피드백 보고서 --------------------\n",
        "def summarize_exam(state: ExamState) -> ExamState:\n",
        "    summary_blocks = []\n",
        "    print(\"\\n\\U0001F4D8 문제풀이 종료 보고서: 문제 풀이 및 정답 확인\")\n",
        "    print(\"=\" * 70)\n",
        "\n",
        "    for i, turn in enumerate(state[\"conversation\"]):\n",
        "        qnum = i + 1\n",
        "        question = turn[\"question\"].get(\"문제\", \"\").strip()\n",
        "        choices = turn[\"question\"].get(\"선택지\", [])\n",
        "        answer = turn[\"answer\"]\n",
        "        eval_result = state[\"evaluation\"][i] if i < len(state[\"evaluation\"]) else {}\n",
        "        correct = eval_result.get(\"정답\", \"\")\n",
        "        result = eval_result.get(\"정답여부\", \"\")\n",
        "        explanation = turn[\"question\"].get(\"해설\", \"해설이 생성되지 않았습니다.\")\n",
        "\n",
        "        # 콘솔 출력\n",
        "        print(f\"[문제 {qnum}] {question}\")\n",
        "        print(\"[선택지]\")\n",
        "        for choice in choices:\n",
        "            print(f\"   {choice}\")\n",
        "        print(f\"[당신의 답변] {answer}\")\n",
        "        print(f\"[정답] {correct}\")\n",
        "        print(f\"[정답 여부] {result}\")\n",
        "        print(f\"[해설] {explanation}\")\n",
        "        print(\"-\" * 70)\n",
        "\n",
        "        # UI용 블록 추가\n",
        "        block = f\"\"\"### 문제 {qnum}\n",
        "**문제:** {question}\n",
        "**내 답:** {answer} / **정답:** {correct} ({result})\n",
        "**해설:** {explanation}\\n\"\"\"\n",
        "        summary_blocks.append(block)\n",
        "\n",
        "        # 해설이 없었다면 생성 (보완)\n",
        "        if \"해설\" not in turn[\"question\"]:\n",
        "            state[\"current_question\"] = turn[\"question\"]\n",
        "            state = generate_explanation(state)\n",
        "            turn[\"question\"] = state[\"current_question\"]\n",
        "\n",
        "    # 모든 요약 텍스트를 하나로 합쳐서 반환용 추가\n",
        "    state[\"final_summary\"] = \"\\n\\n\".join(summary_blocks)\n",
        "    return state\n",
        "\n",
        "# 6) Agent --------------------\n",
        "# 분기 판단 함수\n",
        "def route_next(state: ExamState) -> Literal[\"generate\", \"summarize\"]:\n",
        "    return \"summarize\" if state[\"next_step\"] == \"end\" else \"generate\"\n",
        "\n",
        "# 그래프 정의 시작\n",
        "builder = StateGraph(ExamState)\n",
        "\n",
        "# 노드 추가\n",
        "builder.add_node(\"evaluate\", evaluate_answer)\n",
        "builder.add_node(\"decide\", decide_next_step)\n",
        "builder.add_node(\"generate\", generate_explanation)\n",
        "builder.add_node(\"summarize\", summarize_exam)\n",
        "\n",
        "# 노드 연결\n",
        "builder.set_entry_point(\"evaluate\")\n",
        "builder.add_edge(\"evaluate\", \"decide\")\n",
        "builder.add_conditional_edges(\"decide\", route_next)\n",
        "builder.add_edge(\"generate\", END)      # 루프\n",
        "builder.add_edge(\"summarize\", END)            # 종료\n",
        "\n",
        "# 컴파일\n",
        "graph = builder.compile()\n",
        "#-------------------------------------------------------------------\n",
        "\n",
        "\n",
        "import gradio as gr\n",
        "\n",
        "# 세션 상태 초기화 함수\n",
        "def initialize_state():\n",
        "    return {\n",
        "        \"state\": None,\n",
        "        \"interview_started\": False,\n",
        "        \"interview_ended\": False,\n",
        "        \"chat_history\": []\n",
        "    }\n",
        "\n",
        "# 파일 업로드 후 문제풀이 초기화\n",
        "def upload_and_initialize(file_obj, session_state):\n",
        "    if file_obj is None:\n",
        "        return session_state, [[\"🤖 AI\", \"📂 파일을 업로드해주세요.\"]]\n",
        "\n",
        "    file_path = file_obj.name\n",
        "    state = preProcessing_Exam(file_path)\n",
        "\n",
        "    session_state[\"state\"] = state\n",
        "    session_state[\"interview_started\"] = True\n",
        "\n",
        "    current = state[\"current_question\"]\n",
        "    question_text = current.get(\"문제\", \"\")\n",
        "    case_text = current.get(\"사례\", \"\")\n",
        "    choices_text = \"\\n\".join(current.get(\"선택지\", []))\n",
        "    full_question = f\"{case_text}\\n\\n{question_text}\\n{choices_text}\"\n",
        "\n",
        "    chat_history = [\n",
        "        [\"🤖 AI\", \"문제를 생성 중입니다...\"],\n",
        "        [\"🤖 AI 문제\", full_question]\n",
        "    ]\n",
        "    session_state[\"chat_history\"] = chat_history\n",
        "    full_question = f\"[문제 {current.get('문제번호', '?')}] {case_text}\\n\\n{question_text}\\n{choices_text}\"\n",
        "\n",
        "    return session_state, chat_history\n",
        "\n",
        "# 답변 처리 및 다음 문제 생성\n",
        "def chat_interview(user_input, session_state):\n",
        "    if not session_state[\"interview_started\"]:\n",
        "        return session_state, [[\"🤖 AI\", \"먼저 기출문제를 업로드하고 시작하세요.\"]]\n",
        "\n",
        "    # 사용자 답변 저장\n",
        "    session_state[\"chat_history\"].append([\"🙋‍♂️ 사용자\", user_input])\n",
        "    session_state[\"state\"] = update_current_answer(session_state[\"state\"], user_input)\n",
        "\n",
        "    # 상태 업데이트\n",
        "    session_state[\"state\"] = graph.invoke(session_state[\"state\"])\n",
        "\n",
        "    if session_state[\"state\"][\"next_step\"] == \"end\":\n",
        "        session_state[\"interview_ended\"] = True\n",
        "        session_state[\"state\"] = summarize_exam(session_state[\"state\"])\n",
        "\n",
        "        summary_text = session_state[\"state\"].get(\"final_summary\", \"결과 요약 없음\")\n",
        "        session_state[\"chat_history\"].append([\"🤖 AI 문제\", \"✅ 문제풀이가 종료되었습니다.\\n\\n\" + summary_text])\n",
        "\n",
        "        return session_state, session_state[\"chat_history\"]\n",
        "    else:\n",
        "        current = session_state[\"state\"][\"current_question\"]\n",
        "        question_text = current.get(\"문제\", \"\")\n",
        "        case_text = current.get(\"사례\", \"\")\n",
        "        choices_text = \"\\n\".join(current.get(\"선택지\", []))\n",
        "        qnum = current.get(\"문제번호\", \"?\")\n",
        "        full_question = f\"[문제 {qnum}] {case_text}\\n\\n{question_text}\\n{choices_text}\"\n",
        "\n",
        "        session_state[\"chat_history\"].append([\"🤖 AI 문제\", full_question])\n",
        "        return session_state, session_state[\"chat_history\"]\n",
        "\n",
        "\n",
        "# Gradio UI 구성\n",
        "with gr.Blocks() as demo:\n",
        "    session_state = gr.State(initialize_state())\n",
        "\n",
        "    gr.Markdown(\"# 🧠 AI 문제풀이 시스템\\n기출문제를 업로드하고 수능형 문제를 풀어보세요!\")\n",
        "\n",
        "    with gr.Row():\n",
        "        file_input = gr.File(label=\"기출문제 업로드 (PDF 또는 DOCX)\")\n",
        "        upload_btn = gr.Button(\"문제풀이 시작\")\n",
        "\n",
        "    chatbot = gr.Chatbot()\n",
        "    user_input = gr.Textbox(show_label=False, placeholder=\"답을 ①, ②, ③ 등의 형식으로 입력 후 Enter를 누르세요.\")\n",
        "\n",
        "    upload_btn.click(upload_and_initialize, inputs=[file_input, session_state], outputs=[session_state, chatbot])\n",
        "    user_input.submit(chat_interview, inputs=[user_input, session_state], outputs=[session_state, chatbot])\n",
        "    user_input.submit(lambda: \"\", None, user_input)\n",
        "\n",
        "# 실행\n",
        "demo.launch(share=True)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VvYpBoXHZfvd",
        "outputId": "55f84ebd-af24-4fc0-f6fc-858e0c4867bf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting app.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **3. 실행**"
      ],
      "metadata": {
        "id": "vVw8pSQRyy73"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python app.py"
      ],
      "metadata": {
        "id": "JRnTUFUs_1f8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6da12e44-d7c8-4e69-c9eb-84cf9025c6e6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/app.py:485: UserWarning: You have not specified a value for the `type` parameter. Defaulting to the 'tuples' format for chatbot messages, but this is deprecated and will be removed in a future version of Gradio. Please set type='messages' instead, which uses openai-style dictionaries with 'role' and 'content' keys.\n",
            "  chatbot = gr.Chatbot()\n",
            "* Running on local URL:  http://127.0.0.1:7865\n",
            "* Running on public URL: https://0aa6fa9fd96dd72236.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n",
            "Keyboard interruption in main thread... closing server.\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/gradio/blocks.py\", line 3075, in block_thread\n",
            "    time.sleep(0.1)\n",
            "KeyboardInterrupt\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/app.py\", line 493, in <module>\n",
            "    demo.launch(share=True)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/gradio/blocks.py\", line 2981, in launch\n",
            "    self.block_thread()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/gradio/blocks.py\", line 3079, in block_thread\n",
            "    self.server.close()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/gradio/http_server.py\", line 69, in close\n",
            "    self.thread.join(timeout=5)\n",
            "  File \"/usr/lib/python3.11/threading.py\", line 1123, in join\n",
            "    self._wait_for_tstate_lock(timeout=max(timeout, 0))\n",
            "  File \"/usr/lib/python3.11/threading.py\", line 1139, in _wait_for_tstate_lock\n",
            "    if lock.acquire(block, timeout):\n",
            "       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "KeyboardInterrupt\n",
            "Killing tunnel 127.0.0.1:7865 <> https://0aa6fa9fd96dd72236.gradio.live\n",
            "^C\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "0MTnQq6qKWLi"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}